"""
OrganizeazÄƒ Food-101 Ã®n format PyTorch (train/test folders)
Structura finalÄƒ:
    data/food101_split/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ apple_pie/
    â”‚   â”œâ”€â”€ baby_back_ribs/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ test/
        â”œâ”€â”€ apple_pie/
        â”œâ”€â”€ baby_back_ribs/
        â””â”€â”€ ...
"""
import shutil
from pathlib import Path
import json
from tqdm import tqdm

FOOD101_ROOT = Path("data/food-101")
OUTPUT_ROOT = Path("data/food101_split")

def prepare_splits():
    """OrganizeazÄƒ imaginile Ã®n train/test splits"""
    print("="*70)
    print("ğŸ“ PREPARING TRAIN/TEST SPLITS")
    print("="*70)
    
    # VerificÄƒ dacÄƒ dataset-ul existÄƒ
    if not FOOD101_ROOT.exists():
        print(f"âŒ Error: Food-101 dataset not found at {FOOD101_ROOT.absolute()}")
        print("   Please run 'python download_dataset.py' first!")
        return
    
    # VerificÄƒ dacÄƒ split-ul existÄƒ deja
    if OUTPUT_ROOT.exists():
        print(f"âš ï¸  Output directory already exists: {OUTPUT_ROOT.absolute()}")
        response = input("Do you want to recreate it? (y/n): ")
        if response.lower() != 'y':
            print("Skipping dataset preparation.")
            return
        print("ğŸ§¹ Cleaning existing directory...")
        shutil.rmtree(OUTPUT_ROOT)
    
    # CiteÈ™te split-urile oficiale
    meta_path = FOOD101_ROOT / "meta"
    print(f"\nğŸ“‹ Reading splits from {meta_path}...")
    
    try:
        with open(meta_path / "train.json", "r") as f:
            train_files = json.load(f)
        with open(meta_path / "test.json", "r") as f:
            test_files = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ Error: Could not find meta files: {e}")
        return
    
    # CreeazÄƒ structura de foldere
    train_dir = OUTPUT_ROOT / "train"
    test_dir = OUTPUT_ROOT / "test"
    train_dir.mkdir(parents=True, exist_ok=True)
    test_dir.mkdir(parents=True, exist_ok=True)
    
    images_dir = FOOD101_ROOT / "images"
    
    # CopiazÄƒ imaginile de training
    print("\nğŸ“‚ Organizing TRAINING images...")
    total_train = sum(len(files) for files in train_files.values())
    
    with tqdm(total=total_train, desc="Train images", ncols=100) as pbar:
        for class_name, files in train_files.items():
            class_dir = train_dir / class_name
            class_dir.mkdir(exist_ok=True)
            
            for file_path in files:
                src = images_dir / f"{file_path}.jpg"
                dst = class_dir / f"{Path(file_path).name}.jpg"
                
                if src.exists():
                    shutil.copy2(src, dst)
                    pbar.update(1)
                else:
                    print(f"âš ï¸  Warning: Missing file {src}")
    
    # CopiazÄƒ imaginile de test
    print("\nğŸ“‚ Organizing TEST images...")
    total_test = sum(len(files) for files in test_files.values())
    
    with tqdm(total=total_test, desc="Test images", ncols=100) as pbar:
        for class_name, files in test_files.items():
            class_dir = test_dir / class_name
            class_dir.mkdir(exist_ok=True)
            
            for file_path in files:
                src = images_dir / f"{file_path}.jpg"
                dst = class_dir / f"{Path(file_path).name}.jpg"
                
                if src.exists():
                    shutil.copy2(src, dst)
                    pbar.update(1)
                else:
                    print(f"âš ï¸  Warning: Missing file {src}")
    
    # SalveazÄƒ lista de clase
    classes = sorted(train_files.keys())
    classes_file = OUTPUT_ROOT / "classes.json"
    with open(classes_file, "w") as f:
        json.dump(classes, f, indent=2)
    
    # SalveazÄƒ mapping id2label
    id2label = {i: class_name for i, class_name in enumerate(classes)}
    label2id = {class_name: i for i, class_name in enumerate(classes)}
    
    mapping_file = OUTPUT_ROOT / "class_mapping.json"
    with open(mapping_file, "w") as f:
        json.dump({"id2label": id2label, "label2id": label2id}, f, indent=2)
    
    print("\n" + "="*70)
    print("âœ… DATASET PREPARATION COMPLETE!")
    print("="*70)
    print(f"Location: {OUTPUT_ROOT.absolute()}")
    print(f"\nğŸ“Š Statistics:")
    print(f"   â”œâ”€ Classes: {len(classes)}")
    print(f"   â”œâ”€ Train images: {total_train}")
    print(f"   â”œâ”€ Test images: {total_test}")
    print(f"   â”œâ”€ Total images: {total_train + total_test}")
    print(f"   â””â”€ Class mapping saved: {mapping_file}")
    
    print("\nğŸ¯ Next step: Run 'python train_model.py' to start training!")
    
    # VerificÄƒ cÃ¢teva clase random
    print("\nğŸ“‹ Sample classes:")
    for class_name in classes[:5]:
        train_count = len(list((train_dir / class_name).glob("*.jpg")))
        test_count = len(list((test_dir / class_name).glob("*.jpg")))
        print(f"   â”œâ”€ {class_name}: {train_count} train, {test_count} test")
    print(f"   â””â”€ ... (and {len(classes) - 5} more)")

if __name__ == "__main__":
    try:
        prepare_splits()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Preparation interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
